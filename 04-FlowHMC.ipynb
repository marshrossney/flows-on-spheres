{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3abc0b-8a16-4a87-84dd-66b816466338",
   "metadata": {},
   "source": [
    "# Flow HMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb7eefa-4142-4e36-81e0-3f525cf6b93b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import TypeAlias, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.linalg as LA\n",
    "\n",
    "from distributions import SphericalUniformPrior3D\n",
    "from models import NormalizingFlowRQS, NormalizingFlowC2, DummyNormalizingFlow\n",
    "from transforms import MobiusTransform, RQSplineTransform, RQSplineTransformCircularDomain, C2SplineTransform\n",
    "from utils import metropolis_acceptance, effective_sample_size, spherical_mesh, simple_fnn_conditioner, batched_dot, batched_outer, batched_mv\n",
    "from visualisations import scatter, pairplot\n",
    "\n",
    "Tensor: TypeAlias = torch.Tensor\n",
    "\n",
    "π = math.pi\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bcf534-e0ef-4b1f-ba02-022bcab2352b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def debug_plots(\n",
    "    z: list,\n",
    "    x: list,\n",
    "    p: list,\n",
    "    F: list,\n",
    "    H: list,\n",
    "    S: list,\n",
    "    ldj: list,\n",
    "    *,\n",
    "    n_traj: int,\n",
    "    n_steps: int,\n",
    "    ε: float,\n",
    "    κ: float,\n",
    "    μ: Tensor,\n",
    "    lines: bool,\n",
    "):\n",
    "    z = torch.stack(z, dim=1)\n",
    "    x = torch.stack(x, dim=1)\n",
    "    p = torch.stack(p, dim=1)\n",
    "    F = torch.stack(F, dim=1)\n",
    "    H = torch.stack(H, dim=1)\n",
    "    S = torch.stack(S, dim=1)\n",
    "    ldj = torch.stack(ldj, dim=1)\n",
    "    \n",
    "    modz = LA.vector_norm(z, dim=-1)\n",
    "    modx = LA.vector_norm(x, dim=-1)\n",
    "    modp = LA.vector_norm(p, dim=-1)\n",
    "    modF = LA.vector_norm(F, dim=-1)\n",
    "    \n",
    "    phi_z = torch.fmod(torch.atan2(z[..., 1], z[..., 0]) + 2 * π, 2 * π)\n",
    "    phi_x = torch.fmod(torch.atan2(x[..., 1], x[..., 0]) + 2 * π, 2 * π)\n",
    "    \n",
    "    pdotz = batched_dot(p, z)\n",
    "    Fdotz = batched_dot(F, z)\n",
    "    \n",
    "    grad_ldj = F - κ * μ\n",
    "        \n",
    "    nt = z.shape[1] - 1\n",
    "    t = np.linspace(0, nt * ε, nt + 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(6, 1, sharex=True, figsize=(16, 24), gridspec_kw=dict(hspace=0.1))\n",
    "    for ax in axes:\n",
    "        [ax.axvline(traj_num * n_steps * ε, linestyle=\"--\", color=\"grey\", alpha=0.5) for traj_num in range(1, n_traj)]\n",
    "    \n",
    "    #axes[0].set_xticks(np.arange(n_traj) * n_steps * ε)\n",
    "    \n",
    "    if lines:\n",
    "        ls, ls2 = \"-\", \":\"\n",
    "        m, m2 = \"\", \"\"\n",
    "    else:\n",
    "        ls, ls2 = \"\", \"\"\n",
    "        m, m2 = \"+\", \"x\"\n",
    "    \n",
    "    axes = iter(axes)\n",
    "    \n",
    "    ax = next(axes)\n",
    "    ax.set_ylabel(\"$z \\mid x$\")\n",
    "    for i, zi in zip(range(1, 4), z.split(1, dim=-1)):\n",
    "        ax.plot(t, zi.squeeze(), marker=m, linestyle=ls, label=f\"$z_{i}$\")\n",
    "    ax.plot(t, modz.squeeze(), marker=m, linestyle=ls, label=r\"$|\\mathbf{z}|$\")\n",
    "    ax.set_prop_cycle(None)\n",
    "    for i, xi in zip(range(1, 4), x.split(1, dim=-1)):\n",
    "        ax.plot(t, xi.squeeze(), marker=m2, linestyle=ls2, label=f\"$x_{i}$\")\n",
    "    ax.plot(t, modx.squeeze(), marker=m2, linestyle=ls2, label=r\"$|\\mathbf{x}|$\")\n",
    "    ax.legend(ncols=2)\n",
    "    \n",
    "    ax = next(axes)\n",
    "    ax.set_ylabel(r\"$\\phi_z \\mid \\phi_x$\")\n",
    "    ax.plot(t, phi_z.squeeze(), marker=m, linestyle=ls, label=r\"$\\phi_z$\")\n",
    "    ax.plot(t, phi_x.squeeze(), marker=m2, linestyle=ls, label=r\"$\\phi_x$\")\n",
    "    ax.set_ylim(-0.5, 2 * π + 0.5)\n",
    "    ax.axhline(2 * π, linestyle=\":\")\n",
    "    ax.annotate(r\"$2 \\pi$\", xy=(0, 2 * π), xycoords=\"data\")\n",
    "    ax.legend()\n",
    "    \n",
    "    ax = next(axes)\n",
    "    ax.set_ylabel(\"$p$\")\n",
    "    for i, pi in zip(range(1, 4), p.split(1, dim=-1)):\n",
    "        ax.plot(t, pi.squeeze(), marker=m, linestyle=ls, label=f\"$p_{i}$\")\n",
    "    ax.plot(t, modp.squeeze(), marker=m, linestyle=ls, label=r\"$|\\mathbf{p}|$\")\n",
    "    ax.legend()\n",
    "    \n",
    "    ax = next(axes)\n",
    "    ax.set_ylabel(\"$S \\mid H$\")\n",
    "    ax.plot(t, S.squeeze(), marker=m, linestyle=ls, label=\"$S$\")\n",
    "    ax.plot(t, H.squeeze(), marker=m2, linestyle=ls, label=\"$H$\")\n",
    "    ax.legend()\n",
    "    \n",
    "    ax = next(axes)\n",
    "    ax.set_ylabel(\"$F$\")\n",
    "    for i, Fi in zip(range(1, 4), F.split(1, dim=-1)):\n",
    "        ax.plot(t, Fi.squeeze(), marker=m, linestyle=ls, label=f\"$F_{i}$\")\n",
    "    ax.plot(t, modF.squeeze(), marker=m, linestyle=ls, label=r\"$|\\mathbf{F}|$\")\n",
    "    ax.legend()\n",
    "    \n",
    "    ax = next(axes)\n",
    "    ax.set_ylabel(r\"$\\log \\vert \\partial \\mathbf{x} / \\partial \\mathbf{z} \\vert$\")\n",
    "    label = r\"$\\log \\vert \\partial \\mathbf{x} / \\partial \\mathbf{z} \\vert$\"\n",
    "    ax.plot(t, ldj.squeeze(), marker=m, linestyle=ls, label=label)\n",
    "    for i, gradi in zip(range(1, 4), grad_ldj.split(1, dim=-1)):\n",
    "        ax.plot(t, gradi.squeeze(), marker=m2, linestyle=ls, label=f\"$\\partial / \\partial z_{i}$\" + label)\n",
    "    ax.legend()\n",
    "\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c1be53-6eef-48b5-99bd-019a58375d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def flow_hmc(\n",
    "    trained_model: pl.LightningModule, batch_size: int, n_traj: int, traj_length: int, n_steps: int, κ: Optional[float] = None, μ: Optional[Tensor] = None, debug: bool = False, lines: bool = True,\n",
    "):\n",
    "    flow = trained_model\n",
    "\n",
    "    κ = κ if κ is not None else trained_model.κ\n",
    "    if μ is not None:\n",
    "        μ = μ if isinstance(μ, torch.Tensor) else torch.tensor(μ, dtype=torch.float32)\n",
    "        μ.div_(LA.vector_norm(μ))\n",
    "    μ = μ if μ is not None else trained_model.μ\n",
    "\n",
    "    ε = traj_length / n_steps\n",
    "\n",
    "    # Initial state randomly distributed on the sphere\n",
    "    z0, _ = next(SphericalUniformPrior3D(batch_size))\n",
    "    z0.squeeze_(dim=1)\n",
    "    assert z0.shape == torch.Size([batch_size, 3])\n",
    "\n",
    "    outputs = torch.empty(n_traj, batch_size, 3)\n",
    "\n",
    "    def get_force(z: Tensor) -> Tensor:\n",
    "        z.requires_grad_(True)\n",
    "        z.grad = None\n",
    "        with torch.enable_grad():\n",
    "            x, log_dxdz = flow(z)\n",
    "            S = -κ * torch.mv(x, μ) - log_dxdz\n",
    "            assert S.shape == torch.Size([batch_size])\n",
    "            S.backward(gradient=torch.ones_like(S))\n",
    "        F = z.grad.negative()\n",
    "        z.requires_grad_(False)\n",
    "        z.grad = None\n",
    "        \n",
    "        # For dummy flow these should be equal\n",
    "        #print(\"F - κμ\", F - κ * μ)\n",
    "        \n",
    "        return F\n",
    "\n",
    "    n_accepted = 0\n",
    "    \n",
    "    # Quantities to track for debugging\n",
    "    H_history = []\n",
    "    F_history = []\n",
    "    z_history = []\n",
    "    p_history = []\n",
    "    x_history = []\n",
    "    S_history = []\n",
    "    ldj_history = []\n",
    "\n",
    "    for i in range(n_traj):\n",
    "\n",
    "        z = z0.clone()\n",
    "        \n",
    "        # Initial momenta\n",
    "        p = torch.empty_like(z).normal_()\n",
    "        M = torch.eye(3) - batched_outer(z, z)\n",
    "        p = batched_mv(M, p)\n",
    "        \n",
    "        #assert torch.allclose(batched_mv(M, z), torch.zeros(batch_size), atol=1e-5)\n",
    "        #assert torch.allclose(batched_dot(p, z), torch.zeros(batch_size), atol=1e-5)\n",
    "\n",
    "        x, log_dxdz = flow(z)\n",
    "        S0 = -κ * torch.mv(x, μ) - log_dxdz\n",
    "        H0 = 0.5 * (p ** 2).sum(dim=1) + S0\n",
    "        \n",
    "        # Begin leapfrog\n",
    "\n",
    "        F = get_force(z)\n",
    "        p += 0.5 * ε * batched_mv(M, F)\n",
    "\n",
    "        # print(\"(PRE) |z| = \", LA.vector_norm(z, dim=-1))\n",
    "        # print(\"(PRE) z . π = \", batched_dot(π, z))\n",
    "\n",
    "        if i == 0 and debug:\n",
    "            H_history.append(H0)\n",
    "            F_history.append(F)\n",
    "            z_history.append(z)\n",
    "            p_history.append(p)\n",
    "            x_history.append(x)\n",
    "            S_history.append(S0)\n",
    "            ldj_history.append(log_dxdz)\n",
    "        \n",
    "        for t in range(n_steps):\n",
    "\n",
    "            # Non-trivial coordinate update to preserve unit norm\n",
    "            mod_p = LA.vector_norm(p, dim=-1, keepdim=True)\n",
    "            cos_εp = torch.cos(ε * mod_p)\n",
    "            sin_εp = torch.sin(ε * mod_p)\n",
    "            z_tmp = cos_εp * z + (1 / mod_p) * sin_εp * p\n",
    "            p = -mod_p * sin_εp * z + cos_εp * p\n",
    "            z = z_tmp\n",
    "\n",
    "            #print(\"|z| = \", LA.vector_norm(z, dim=-1))\n",
    "            #print(\"z . p = \", batched_dot(p, z))\n",
    "\n",
    "            F = get_force(z)\n",
    "            M = torch.eye(3) - batched_outer(z, z)\n",
    "            if t == n_steps - 1:\n",
    "                p += 0.5 * ε * batched_mv(M, F)\n",
    "            else:\n",
    "                p += ε * batched_mv(M, F)\n",
    "                \n",
    "            if debug:\n",
    "                x, log_dxdz = flow(z)\n",
    "                S = -κ * torch.mv(x, μ) - log_dxdz\n",
    "                H = 0.5 * (p ** 2).sum(dim=1) + S\n",
    "                H_history.append(H)\n",
    "                F_history.append(F)\n",
    "                z_history.append(z)\n",
    "                p_history.append(p)\n",
    "                x_history.append(x)\n",
    "                S_history.append(S)\n",
    "                ldj_history.append(log_dxdz)\n",
    "\n",
    "        x, log_dxdz = flow(z)\n",
    "        HT = 0.5 * (p ** 2).sum(dim=1) - κ * torch.mv(x, μ) - log_dxdz\n",
    "\n",
    "        accepted = (H0 - HT).clamp(max=0).exp() > torch.rand_like(H0)\n",
    "        n_accepted += accepted.sum()\n",
    "\n",
    "        z0[accepted] = z[accepted]\n",
    "        \n",
    "        x, _ = flow(z0)\n",
    "        outputs[i] = x\n",
    "\n",
    "    acceptance_rate = n_accepted / (batch_size * n_traj)\n",
    "    print(\"acceptance: \", acceptance_rate)\n",
    "    \n",
    "    if debug:\n",
    "        _ = debug_plots(\n",
    "            z_history,\n",
    "            x_history,\n",
    "            p_history,\n",
    "            F_history,\n",
    "            H_history,\n",
    "            S_history,\n",
    "            ldj_history,\n",
    "            n_traj=n_traj,\n",
    "            n_steps=n_steps,\n",
    "            ε=ε,\n",
    "            κ=κ,\n",
    "            μ=μ,\n",
    "            lines=lines,\n",
    "        )\n",
    "        \n",
    "    return outputs.transpose(0, 1)  # (batch_size, n_traj, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c6ab73-4054-4ac4-a1b6-2d756e5e8791",
   "metadata": {},
   "source": [
    "## Test the algorithm with a dummy model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccca9769-a014-4ee2-aca3-c901afc51da2",
   "metadata": {},
   "source": [
    "### Uniform target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5d51e8-604e-4651-a095-278345836b49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_model = DummyNormalizingFlow()\n",
    "    \n",
    "x_from_flow_hmc = flow_hmc(dummy_model, batch_size=1, n_traj=8, traj_length=1, n_steps=50, κ = 0.001, μ = [0, 0, 1], debug=True, lines=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b34fc5-8529-4a16-86b1-96572a0a7e89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z, _ = next(SphericalUniformPrior3D(5000))\n",
    "    z.squeeze_(dim=1)\n",
    "    x_from_model, _ = dummy_model(z)\n",
    "\n",
    "x_from_flow_hmc = flow_hmc(dummy_model, batch_size=10, n_traj=500, traj_length=1, n_steps=4, κ = 0.001, μ = [0, 0, 1], debug=False)\n",
    "#x_from_flow_hmc = x_from_flow_hmc.flatten(start_dim=0, end_dim=1)\n",
    "\n",
    "fig1 = scatter(x_from_model, s=2)\n",
    "fig1.suptitle(\"Data Generated by Normalizing Flow\")\n",
    "\n",
    "fig2 = scatter(x_from_flow_hmc, s=2)\n",
    "fig2.suptitle(\"Data Generated by Flow HMC\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9ab2de-20b5-48bb-90f3-68d0f3b5915c",
   "metadata": {},
   "source": [
    "### Concentrated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c73fda5-8386-4bab-8a76-a49f700499f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dummy_model = DummyNormalizingFlow()\n",
    "\n",
    "x_from_flow_hmc = flow_hmc(dummy_model, batch_size=1, n_traj=8, traj_length=1, n_steps=50, κ = 10, μ = [1, -1, 1], debug=True, lines=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4288db2-e393-4791-adbd-ce9f14c7d407",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_from_flow_hmc = flow_hmc(dummy_model, batch_size=10, n_traj=500, traj_length=1, n_steps=4, κ = 10, μ = [1, -1, 1], debug=False)\n",
    "#x_from_flow_hmc = x_from_flow_hmc.flatten(start_dim=0, end_dim=1)\n",
    "\n",
    "fig1 = scatter(x_from_model, s=2)\n",
    "fig1.suptitle(\"Data Generated by Normalizing Flow\")\n",
    "\n",
    "fig2 = scatter(x_from_flow_hmc, s=2)\n",
    "fig2.suptitle(\"Data Generated by Flow HMC\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc453b3-1115-4543-ba45-67e201f48819",
   "metadata": {},
   "source": [
    "## Rational Quadratic Splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f39e0b-c04b-4cdf-8bc0-fb5fb6e06be8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ckpt_path = \"tb_logs/rq_spline/version_1/checkpoints/last.ckpt\"\n",
    "\n",
    "model = NormalizingFlowRQS.load_from_checkpoint(ckpt_path)\n",
    "print(model.hparams)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    max_steps=4000,\n",
    "    val_check_interval=500,\n",
    "    limit_val_batches=1,\n",
    "    limit_test_batches=1,\n",
    "    num_sanity_val_steps=1,\n",
    "    logger=False,\n",
    ")\n",
    "\n",
    "(metrics,) = trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf89bffe-4728-41fd-8a67-5ba3f6d9ca38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_from_flow_hmc = flow_hmc(model, batch_size=1, n_traj=8, traj_length=1, n_steps=100, debug=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03e5a24-728b-4e9d-82b9-378a7fb96edd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z, _ = next(SphericalUniformPrior3D(5000))\n",
    "    z.squeeze_(dim=1)\n",
    "    x_from_model, _ = model(z)\n",
    "\n",
    "x_from_flow_hmc = flow_hmc(model, batch_size=10, n_traj=500, traj_length=1, n_steps=10, debug=False)\n",
    "#x_from_flow_hmc = x_from_flow_hmc.flatten(start_dim=0, end_dim=1)\n",
    "\n",
    "fig1 = scatter(x_from_model, s=2)\n",
    "fig1.suptitle(\"Data Generated by Normalizing Flow\")\n",
    "\n",
    "fig2 = scatter(x_from_flow_hmc, s=2)\n",
    "fig2.suptitle(\"Data Generated by Flow HMC\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bed38b7-4391-4d6c-ba91-74a6262f3fc7",
   "metadata": {},
   "source": [
    "## C2 Splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e90de3c-c419-41d5-910f-ed2a77c1faab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ckpt_path = \"tb_logs/c2_spline/version_1/checkpoints/last.ckpt\"\n",
    "\n",
    "model = NormalizingFlowC2.load_from_checkpoint(ckpt_path)\n",
    "print(model.hparams)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    max_steps=4000,\n",
    "    val_check_interval=500,\n",
    "    limit_val_batches=1,\n",
    "    limit_test_batches=1,\n",
    "    num_sanity_val_steps=1,\n",
    "    logger=False,\n",
    ")\n",
    "\n",
    "(metrics,) = trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c684e430-8cd8-4f88-8af4-23ede7b6692c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_from_flow_hmc = flow_hmc(model, batch_size=1, n_traj=8, traj_length=1, n_steps=100, debug=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b17764c-e52d-4e46-84e9-ca95a695d40f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z, _ = next(SphericalUniformPrior3D(5000))\n",
    "    z.squeeze_(dim=1)\n",
    "    x_from_model, _ = model(z)\n",
    "\n",
    "x_from_flow_hmc = flow_hmc(model, batch_size=10, n_traj=500, traj_length=1, n_steps=10, debug=False)\n",
    "#x_from_flow_hmc = x_from_flow_hmc.flatten(start_dim=0, end_dim=1)\n",
    "\n",
    "fig1 = scatter(x_from_model, s=2)\n",
    "fig1.suptitle(\"Data Generated by Normalizing Flow\")\n",
    "\n",
    "fig2 = scatter(x_from_flow_hmc, s=2)\n",
    "fig2.suptitle(\"Data Generated by Flow HMC\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
